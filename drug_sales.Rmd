#Loading libraries
library(tidyverse)
library(rstatix)
library(lubridate)
library(fpp3)

#Loading data 
pharma_sales <- read_csv("/Users/Elias/Downloads/Portfolio/salesmonthly.csv")

head(pharma_sales)

#Checking for duplicate rows
pharma_sales |> 
  group_by(across(everything())) |> 
  filter(n() > 1)

#Checking for regularity
pharma_sales1 <- pharma_sales |> 
  mutate(datum = floor_date(datum, unit = "month")) |> 
  complete(datum = seq(min(datum), max(datum), by = "month"))

head(pharma_sales1)

#Checking for null values
pharma_sales1 |> 
  filter(if_any(everything(), is.na))

#Checking for outliers
##We have no outliers for R06
for(i in 2:ncol(pharma_sales1)){
  outliers <- identify_outliers(pharma_sales1[i])
  print(outliers)
}

#Converting to tsibble object
pharma_sales2 <- pharma_sales1 |>
  mutate(Month = yearmonth(datum)) |> 
  select(-datum) |> 
  as_tsibble(
    index = Month
  )

head(pharma_sales2)

#Investigating trend and seasonality
##There is seasonality. We must investigate further.
pharma_sales2 |> 
  autoplot(R06) +
  labs(title = "Time Plot: R06 Drug Sales", y = "Number of Sales")

#Investigating seasonality further
##There is a sharp increase in sales from Jan - May and a gradual decrease in sales from May - December every year.
pharma_sales2 |> 
gg_season(R06) + 
  labs(title = "Seasonal Plot: R06 Drug Sales", y = "Number of Sales", color = "Year")

#Creating train and test sets
train <- pharma_sales2 |> filter(year(Month) <= 2017)
test <- pharma_sales2 |> filter(year(Month) > 2017)

#Creating a benchmark model: Seasonal Naive
fit_snaive <- train |> 
  model(SNAIVE = SNAIVE(R06))

#Fitting models: ARIMA
##Because of the seasonality, we will apply seasonal difference to stabilize.  
train |>
  gg_tsdisplay(difference(R06, 12), plot_type = 'partial', lag = 12) +
  labs(title = "Seasonally Differenced", y = "")

##Now we must check if our data is stationary
##We fail to reject the null. Our data is stationary.
train |> features(difference(R06, 12), unitroot_kpss) 

##Based on our findings, the automatically selected ARIMA model should be similar to ARIMA(0,0,0)(0,1,1)[12] 
fit_arima <- train |> 
  model(ARIMA = ARIMA(R06, stepwise = FALSE, approximation = FALSE))
fit_arima |> pivot_longer(everything(), names_to = "Model name", values_to = "Orders")

#Fitting models: ETS
fit_ets <- train |> 
  model(ETS = ETS(R06))

fit_ets1 <- pharma_sales2 |> 
  select(R06) |> 
  model(ETS = ETS(R06))

#Using one-step forecasts to see which model fits the best
##Based on our accuracy metrics, the ETS model fits the best.
fit_snaive |> 
  refit(test) |>
  accuracy()

fit_arima |>
  refit(test) |>
  accuracy()

fit_ets |>
  refit(test) |>
  accuracy()

#Forecasting
fit_ets |>
  forecast(h = nrow(test)) |>
  autoplot(pharma_sales2 |> select(R06)) +
  labs(title = "Forecast: R06 Drug Sales", y = "Number of Sales")

#You can follow the same process above for the other drugs. You can also try more advanced models like prophet, vector autoregressions, and neural network to see if they better fit the data. 
